use_gpu: True
device: 1
early_stop:
  patience: 5
federate:
  mode: standalone
  method : shadow
  total_round_num: 30000
  client_num: 16 # 6040
  sample_client_num: 16
  sample_client_rate: -1.0
  make_global_eval : False
  save_to: "../../../../data1/donghoon/FederatedScopeData/exp/ml-1m/0823_rand-replace-aug_20_1e-1_hidden_size_64_CE_lr1-e4_epoch_1_shadow_round_30K.pt"
  standalone_args :
    use_shadow : True
    shadow_client_num : 6040
    use_one_hop_eval : True
data:
  root: ../../../../data1/donghoon/FederatedScopeData/ml-1m/
  partitioned_df_path : '../../../../data1/donghoon/FederatedScopeData/ml-1m/random_augmented_0.1'
  type: sr_data
  consistent_label_distribution: False ## This can be only used when the datasets are sorted by user_ids
  splitter : sr_splitter
  augmentation_column : 'augmentation_idx:token'
  use_augmentation : True
  max_augmentation_idx : 20 ## 1 + 20 augmentations
dataloader :
  type : base
  batch_size : 1
model:
  type: sasrec
  hidden_dropout_prob: 0.0
  attn_dropout_prob: 0.0
train:
  batch_or_epoch : 'epoch'
  local_update_steps: 1
  optimizer:
    lr: 0.001
criterion:
  type: CrossEntropyLoss
trainer:
  type: sasrec_trainer
eval:
  freq: 250
  metrics: ['recall_10','recall_20','ndcg_10','ndcg_20']
  split : ['val', 'test']
  best_res_update_round_wise_key: test_avg_loss
  count_flops: False