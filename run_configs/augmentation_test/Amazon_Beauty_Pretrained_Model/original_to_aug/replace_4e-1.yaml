use_gpu: True
device: 1
early_stop:
  patience: 1000
federate:
  mode: standalone
  method : shadow
  total_round_num: 30000
  client_num: 16 # 6040
  sample_client_num: 16
  sample_client_rate: -1.0
  make_global_eval : True
  save_to: "../../../../data1/donghoon/FederatedScopeData/exp/amazon_beauty/0909_pretrained_origianl_to_random_replacing_4e-1.pt"
  standalone_args :
    use_shadow : True
    shadow_client_num : 22363
    use_one_hop_eval : True
data:
  root: ../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/
  partitioned_df_path : '../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/random_replacing_0.4'
  type: sr_data
  consistent_label_distribution: False ## This can be only used when the datasets are sorted by user_ids
  min_sequence_length: 5
  max_sequence_length: 50
  user_num: 22363
  item_num: 12101
  splitter : sr_splitter
  augmentation_column : 'augmentation_idx:token'
  use_augmentation : True
  max_augmentation_idx : 10 ## 1 + 10 augmentations
dataloader :
  type : base
  batch_size : 1
model:
  type: sasrec
  hidden_dropout_prob: 0.0
  attn_dropout_prob: 0.0
  hidden_size : 64
  item_num : 12101
  pretrained_model_path : "../../../../data1/donghoon/FederatedScopeData/exp/amazon_beauty/0905_30K_rounds_hidden_size_64_lr1-e3_batch_20_shadow_runner_CE.pt"
train:
  batch_or_epoch : 'batch'
  local_update_steps: 20
  optimizer:
    lr: 0.01
criterion:
  type: CrossEntropyLoss
trainer:
  type: sasrec_trainer
eval:
  freq: 1000
  metrics: ['recall_10','recall_20','ndcg_10','ndcg_20']
  split : ['val', 'test']
  best_res_update_round_wise_key: test_avg_loss
  count_flops: False
