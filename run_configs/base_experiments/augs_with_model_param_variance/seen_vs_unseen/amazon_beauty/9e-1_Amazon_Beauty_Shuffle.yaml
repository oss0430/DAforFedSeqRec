use_gpu: True
device: 2
early_stop:
  patience: 1000
federate:
  mode: standalone
  method : shadow
  unseen_clients_rate : 0.9
  total_round_num: 3000
  client_num: 16 # 6040
  sample_client_num: 16
  sample_client_rate: -1.0
  make_global_eval : True
  save_to: "../../../../data1/donghoon/FederatedScopeData/exp/amazon_beauty/1029_step_20_unseen_9e-1_Shuffle.pt"
  standalone_args :
    use_shadow : True
    shadow_client_num : 22363
    use_one_hop_eval : True
aggregator:
  robust_rule : fedavg_variance
data:
  root: ../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/
  partitioned_df_path : '../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/split' ## not going to use
  type: sr_data
  consistent_label_distribution: False ## This can be only used when the datasets are sorted by user_ids
  splitter : sr_splitter
  min_sequence_length: 5
  max_sequence_length: 50
  user_num: 22363
  item_num: 12101
  augmentation_args :
    augmentation_column : 'augmentation_idx:token'
    use_augmentation : True
    max_augmentation_idx : 9 ## load all augmentations
    is_zero_original : False
    is_multiple : True
    aug_types_count : 2 ## aug types
    df_paths : ['../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/split',
                '../../../../data1/donghoon/FederatedScopeData/Amazon_Beauty_5core/shuffle_no_original']
dataloader :
  type : base
  batch_size : 1
model:
  type: sasrec
  hidden_dropout_prob: 0.0
  attn_dropout_prob: 0.0
  pretrained_model_path : ''
  hidden_size: 64
  item_num : 12101
train:
  batch_or_epoch : 'batch'
  local_update_steps: 20
  optimizer:
    lr: 0.01
criterion:
  type: CrossEntropyLoss
trainer:
  type: sasrec_trainer
eval:
  freq: 1000
  metrics: ['recall_10','recall_20','ndcg_10','ndcg_20']
  split : ['val', 'test']
  best_res_update_round_wise_key: test_avg_loss
  count_flops: False
